{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dHvWOCBbb64B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZB_meh3QHq"
      },
      "source": [
        "Adopted DataLoader from Training file. This will help us to set up calibration data for quantization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHCKeKIHc2WW",
        "outputId": "b3b6eb9d-898c-4af0-8f53-2070c6e6d04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/rn/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 20.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/rn/cifar-10-python.tar.gz to /content/rn\n"
          ]
        }
      ],
      "source": [
        "#data loader adopted from training\n",
        "def data_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    random_seed=42,\n",
        "                    valid_size=0.1,\n",
        "                    shuffle=True,\n",
        "                    test=False):\n",
        "\n",
        "        normalize = transforms.Normalize(\n",
        "            mean=[0.4914, 0.4822, 0.4465],\n",
        "            std=[0.2023, 0.1994, 0.2010],\n",
        "        )\n",
        "\n",
        "        # define transforms\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        download = not os.path.exists(os.path.join(data_dir, \"cifar-10-batches-py\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if test:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=False,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "        else:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=True,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            data, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "\n",
        "calib_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=64,\n",
        "                                  test=False)\n",
        "test_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=64,\n",
        "                                  test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xjyxo2b3j37"
      },
      "source": [
        "Quantized version of the same ResNet20 Architecture. I added nn.quantized.FloatFunctional instead of add(). I added QuantStub and DeQuantStub for conversion to Int8. We should also fuse conv, bn for better results(fuse_modules)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wqvWmJqFeCVD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.quantized as nnq\n",
        "import torch.quantization\n",
        "import torch.nn.init as init\n",
        "class QuantResidualBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "            super(QuantResidualBlock, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)\n",
        "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "            self.relu=nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = downsample\n",
        "            self.out_channels = out_channels\n",
        "            self.skip_add = nn.quantized.FloatFunctional()\n",
        "        def forward(self, x):\n",
        "            residual = x\n",
        "            y = self.conv1(x)\n",
        "            y = self.bn1(y)\n",
        "            y = self.relu(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            if self.downsample:\n",
        "                residual = self.downsample(x)\n",
        "            out = self.skip_add.add(y, residual)\n",
        "            out = self.relu(out)\n",
        "            return out\n",
        "\n",
        "class QuantResNet(nn.Module):\n",
        "        def __init__(self, block, layers, num_classes = 10):\n",
        "            super(QuantResNet, self).__init__()\n",
        "            self.inplanes = 16\n",
        "            self.quant = torch.quantization.QuantStub()\n",
        "            self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1)\n",
        "            self.bn1 = nn.BatchNorm2d(16)\n",
        "            self.relu=nn.ReLU()\n",
        "            #self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "            self.layer0 = self._make_layer(block, 16, layers[0], stride = 1)\n",
        "            self.layer1 = self._make_layer(block, 32, layers[1], stride = 2)\n",
        "            self.layer2 = self._make_layer(block, 64, layers[2], stride = 2)\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "            self.fc = nn.Linear(64, num_classes)\n",
        "            self._initialize_weights()\n",
        "            self.dequant = torch.quantization.DeQuantStub()\n",
        "        def _initialize_weights(self):\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                    if m.bias is not None:\n",
        "                        init.zeros_(m.bias)\n",
        "\n",
        "        def _make_layer(self, block, planes, blocks, stride=1):\n",
        "            downsample = None\n",
        "            if stride != 1 or self.inplanes != planes:\n",
        "\n",
        "                downsample = nn.Sequential(\n",
        "                    nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                    nn.BatchNorm2d(planes),\n",
        "                )\n",
        "            layers = []\n",
        "            layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "            self.inplanes = planes\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.quant(x)\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            #x = self.maxpool(x)\n",
        "            x = self.layer0(x)\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "            x = self.dequant(x)\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsMd8Hdveihi",
        "outputId": "59e31103-f956-409f-9bf3-c30df402b323"
      },
      "outputs": [],
      "source": [
        "model = QuantResNet(QuantResidualBlock, [3, 3, 3])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-EpwECG4cHp"
      },
      "source": [
        "We use the quantized architectu but use the same weights from orginal ResNet. We don't need to train again. This is called PTQ(Post Training Quantization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6amrxnreFJN",
        "outputId": "96599704-3703-411b-90a2-57c1a879383d"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "checkpoint = torch.load(\"/content/resnet20_fast.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "#model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "#model.qconfig = torch.quantization.default_qconfig\n",
        "model.qconfig = torch.quantization.QConfig(\n",
        "    activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8),\n",
        "    weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8)\n",
        ")\n",
        "\n",
        "\n",
        "modules = [\n",
        "    ['conv1', 'bn1', 'relu'],\n",
        "    ['layer0.0.conv1', 'layer0.0.bn1'],\n",
        "    ['layer0.0.conv2', 'layer0.0.bn2'],\n",
        "    ['layer0.1.conv1', 'layer0.1.bn1'],\n",
        "    ['layer0.1.conv2', 'layer0.1.bn2'],\n",
        "    ['layer0.2.conv1', 'layer0.2.bn1'],\n",
        "    ['layer0.2.conv2', 'layer0.2.bn2'],\n",
        "    ['layer1.0.conv1', 'layer1.0.bn1'],\n",
        "    ['layer1.0.conv2', 'layer1.0.bn2'],\n",
        "    ['layer1.0.downsample.0', 'layer1.0.downsample.1'],\n",
        "    ['layer1.1.conv1', 'layer1.1.bn1'],\n",
        "    ['layer1.1.conv2', 'layer1.1.bn2'],\n",
        "    ['layer1.2.conv1', 'layer1.2.bn1'],\n",
        "    ['layer1.2.conv2', 'layer1.2.bn2'],\n",
        "    ['layer2.0.conv1', 'layer2.0.bn1'],\n",
        "    ['layer2.0.conv2', 'layer2.0.bn2'],\n",
        "    ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
        "    ['layer2.1.conv1', 'layer2.1.bn1'],\n",
        "    ['layer2.1.conv2', 'layer2.1.bn2'],\n",
        "    ['layer2.2.conv1', 'layer2.2.bn1'],\n",
        "    ['layer2.2.conv2', 'layer2.2.bn2'],\n",
        "]\n",
        "\n",
        "model = torch.quantization.fuse_modules(model, modules)\n",
        "model.eval()\n",
        "model_prepared = torch.quantization.prepare(model)\n",
        "print(\"Number of observers:\", len([m for m in model_prepared.modules() if 'Observer' in str(type(m))]))\n",
        "model_prepared.eval()\n",
        "with torch.no_grad():\n",
        "    for batch, _ in calib_loader:\n",
        "        batch = batch.to('cpu')\n",
        "        model_prepared(batch)\n",
        "\n",
        "quantized_model = torch.quantization.convert(model_prepared)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAoZQ4pD5Mv3",
        "outputId": "de57c7e1-f238-4486-ce06-9fded1b0e4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuantResNet(\n",
            "  (quant): Quantize(scale=tensor([0.0203]), zero_point=tensor([120]), dtype=torch.quint8)\n",
            "  (conv1): QuantizedConvReLU2d(3, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.03401070460677147, zero_point=0, padding=(1, 1))\n",
            "  (bn1): Identity()\n",
            "  (relu): Identity()\n",
            "  (layer0): Sequential(\n",
            "    (0): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.054778438061475754, zero_point=146, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.07266166806221008, zero_point=132, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.0802651196718216, zero_point=113\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.049193125218153, zero_point=131, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.04578913375735283, zero_point=144, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.07616990059614182, zero_point=86\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.0466272309422493, zero_point=139, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.051416702568531036, zero_point=136, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.07872934639453888, zero_point=75\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.04700416699051857, zero_point=123, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04961373284459114, zero_point=115, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (downsample): Sequential(\n",
            "        (0): QuantizedConv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), scale=0.04710911959409714, zero_point=119)\n",
            "        (1): Identity()\n",
            "      )\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.069901242852211, zero_point=97\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04505522549152374, zero_point=135, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04738425463438034, zero_point=121, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.07554928958415985, zero_point=76\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04118560254573822, zero_point=138, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04572034999728203, zero_point=138, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.08157134801149368, zero_point=65\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), scale=0.04121033102273941, zero_point=128, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.04592205584049225, zero_point=123, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (downsample): Sequential(\n",
            "        (0): QuantizedConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), scale=0.03523916378617287, zero_point=132)\n",
            "        (1): Identity()\n",
            "      )\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.06554558128118515, zero_point=126\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.039026062935590744, zero_point=124, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05003148689866066, zero_point=126, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.06601060181856155, zero_point=94\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): QuantResidualBlock(\n",
            "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05339294299483299, zero_point=101, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): ReLU()\n",
            "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0664975494146347, zero_point=104, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (skip_add): QFunctional(\n",
            "        scale=0.0966947004199028, zero_point=72\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): QuantizedLinear(in_features=64, out_features=10, scale=0.1155988946557045, zero_point=91, qscheme=torch.per_tensor_affine)\n",
            "  (dequant): DeQuantize()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKlTJXam4t17"
      },
      "source": [
        "This model is now tested on 10000 test images. We will check inference speed and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTQHWyAtfS64",
        "outputId": "d58e955c-f154-464e-cd43-de320efa9076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized ACC:  81.08999999999999 Average Inference on Quantized:  0.0019118833780288696\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "quantized_model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = quantized_model(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"Quantized ACC: \", acc*100, \"Average Inference on Quantized: \", t_av)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iF7TerVt53KE"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "class ResidualBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "            super(ResidualBlock, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)\n",
        "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "            self.relu=nn.ReLU()\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = downsample\n",
        "            self.out_channels = out_channels\n",
        "            #self.skip_add = nn.quantized.FloatFunctional()\n",
        "        def forward(self, x):\n",
        "            residual = x\n",
        "            y = self.conv1(x)\n",
        "            y = self.bn1(y)\n",
        "            y = self.relu(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            if self.downsample:\n",
        "                residual = self.downsample(x)\n",
        "            y += residual\n",
        "            y = self.relu(y)\n",
        "            return y\n",
        "class ResNet(nn.Module):\n",
        "        def __init__(self, block, layers, num_classes = 10):\n",
        "            super(ResNet, self).__init__()\n",
        "            self.inplanes = 16\n",
        "            #self.quant = torch.quantization.QuantStub()\n",
        "            self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1)\n",
        "            self.bn1 = nn.BatchNorm2d(16)\n",
        "            self.relu=nn.ReLU()\n",
        "            #self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "            self.layer0 = self._make_layer(block, 16, layers[0], stride = 1)\n",
        "            self.layer1 = self._make_layer(block, 32, layers[1], stride = 2)\n",
        "            self.layer2 = self._make_layer(block, 64, layers[2], stride = 2)\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "            self.fc = nn.Linear(64, num_classes)\n",
        "            self._initialize_weights()  # Apply He initialization\n",
        "            #self.dequant = torch.quantization.DeQuantStub()\n",
        "        def _initialize_weights(self):\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                    if m.bias is not None:\n",
        "                        init.zeros_(m.bias)\n",
        "\n",
        "        def _make_layer(self, block, planes, blocks, stride=1):\n",
        "            downsample = None\n",
        "            if stride != 1 or self.inplanes != planes:\n",
        "\n",
        "                downsample = nn.Sequential(\n",
        "                    nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                    nn.BatchNorm2d(planes),\n",
        "                )\n",
        "            layers = []\n",
        "            layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "            self.inplanes = planes\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        def forward(self, x):\n",
        "            #x = self.quant(x)\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            #x = self.maxpool(x)\n",
        "            x = self.layer0(x)\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "            #x = self.dequant(x)\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdoU3BU_1xJs",
        "outputId": "ff263547-9995-4def-868e-31dc9d70592e"
      },
      "outputs": [],
      "source": [
        "modelq = ResNet(ResidualBlock, [3,3,3])\n",
        "checkpoint = torch.load(\"/content/resnet20_fast.pth\", map_location=\"cpu\")\n",
        "modelq.load_state_dict(checkpoint)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkh9JPPt7Sl_",
        "outputId": "da61e1bc-88af-49e5-c357-39667db2b6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FP32 orginal model ACC:  81.3 Average Inference on FP32:  0.0026718903303146364\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "modelq.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = modelq(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"FP32 orginal model ACC: \", acc*100, \"Average Inference on FP32: \", t_av)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Our Scores\n",
        "\n",
        "Accuracy Retention = (Quantized Accuracy / Original Accuracy) × 100\n",
        "                   = *99.74%*\n",
        "\n",
        "Inference Time=( Original Inference Time/ Quantized Inference Time)\n",
        "              = *1.397x*\n",
        "\n",
        "Overall = Accuracy Retention/100 + Inference Speedup/5 = 1.2768\n",
        "\n",
        "Lets look at the others!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
