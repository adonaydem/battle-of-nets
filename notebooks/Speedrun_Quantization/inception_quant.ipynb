{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ryFBsbciXJwl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AHVvqUxXKmh",
        "outputId": "738015ef-25fc-4c59-a3eb-3605437daadf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 46.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#data loader adopted from training\n",
        "def data_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    random_seed=42,\n",
        "                    valid_size=0.1,\n",
        "                    shuffle=True,\n",
        "                    test=False):\n",
        "\n",
        "        normalize = transforms.Normalize(\n",
        "            mean=[0.4914, 0.4822, 0.4465],\n",
        "            std=[0.2023, 0.1994, 0.2010],\n",
        "        )\n",
        "\n",
        "        # define transforms\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        download = not os.path.exists(os.path.join(data_dir, \"cifar-10-batches-py\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if test:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=False,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "        else:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=True,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            data, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "\n",
        "calib_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=32,\n",
        "                                  test=False)\n",
        "test_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=32,\n",
        "                                  test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIO8DrmELW4H"
      },
      "source": [
        "Architecture adopted from inceptionnet.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q2f1lhCRzhHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(InceptionNet, self).__init__()\n",
        "        self.in_channels = 3\n",
        "\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(64)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        #ib1\n",
        "\n",
        "        #1X1\n",
        "        #for 3x3\n",
        "        self.conv2_1 = nn.Conv2d(64, 32, kernel_size=1, padding='same')\n",
        "        self.bn2_1 = nn.BatchNorm2d(32)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 5x5\n",
        "        self.conv2_2 = nn.Conv2d(64, 8, kernel_size=1, padding='same')\n",
        "        self.bn2_2 = nn.BatchNorm2d(8)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "        #maxpool\n",
        "        self.pool2_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        #3x3\n",
        "        self.conv2_4 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "        self.bn2_4 = nn.BatchNorm2d(64)\n",
        "        self.relu2_4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #5x5\n",
        "        self.conv2_5 = nn.Conv2d(8, 16, kernel_size=5, padding='same')\n",
        "        self.bn2_5 = nn.BatchNorm2d(16)\n",
        "        self.relu2_5 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 1x1\n",
        "        self.conv2_3 = nn.Conv2d(64, 32, kernel_size=1, padding='same')\n",
        "        self.bn2_3 = nn.BatchNorm2d(32)\n",
        "        self.relu2_3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #after maxpool\n",
        "        self.conv2_6 = nn.Conv2d(64, 16, kernel_size=1, padding='same')\n",
        "        self.bn2_6 = nn.BatchNorm2d(16)\n",
        "        self.relu2_6 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #ib2\n",
        "\n",
        "        #1X1\n",
        "        #for 3x3\n",
        "        self.conv3_1 = nn.Conv2d(128, 64, kernel_size=1, padding='same')\n",
        "        self.bn3_1 = nn.BatchNorm2d(64)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 5x5\n",
        "        self.conv3_2 = nn.Conv2d(128, 16, kernel_size=1, padding='same')\n",
        "        self.bn3_2 = nn.BatchNorm2d(16)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 1x1\n",
        "        self.conv3_3 = nn.Conv2d(128, 64, kernel_size=1, padding='same')\n",
        "        self.bn3_3 = nn.BatchNorm2d(64)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #maxpool\n",
        "        self.pool3_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        #3x3\n",
        "        self.conv3_4 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "        self.bn3_4 = nn.BatchNorm2d(128)\n",
        "        self.relu3_4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #5x5\n",
        "        self.conv3_5 = nn.Conv2d(16, 32, kernel_size=5, padding='same')\n",
        "        self.bn3_5 = nn.BatchNorm2d(32)\n",
        "        self.relu3_5 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #after maxpool\n",
        "        self.conv3_6 = nn.Conv2d(128, 32, kernel_size=1, padding='same')\n",
        "        self.bn3_6 = nn.BatchNorm2d(32)\n",
        "        self.relu3_6 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        #final averagePool\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=8, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 2048)\n",
        "        self.relu_fc1 = nn.ReLU(inplace=True)\n",
        "        # self.fc2 = nn.Linear(4096, 4096)\n",
        "        # self.relu_fc2 = nn.ReLU(inplace=True)\n",
        "        self.fc3 = nn.Linear(2048, num_classes)\n",
        "\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.relu1_1(self.bn1_1(self.conv1_1(x)))\n",
        "      x = self.relu1_2(self.bn1_2(self.conv1_2(x)))\n",
        "      x = self.pool1(x)\n",
        "\n",
        "      x_3x3 = self.relu2_1(self.bn2_1(self.conv2_1(x)))\n",
        "      x_5x5 = self.relu2_2(self.bn2_2(self.conv2_2(x)))\n",
        "      x_1x1 = self.relu2_3(self.bn2_3(self.conv2_3(x)))\n",
        "      x_pool = self.pool2_1(x)\n",
        "\n",
        "      x_3x3 = self.relu2_4(self.bn2_4(self.conv2_4(x_3x3)))\n",
        "      x_5x5 = self.relu2_5(self.bn2_5(self.conv2_5(x_5x5)))\n",
        "      x_pool = self.relu2_6(self.bn2_6(self.conv2_6(x_pool)))\n",
        "\n",
        "      x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n",
        "      x = self.maxpool(x)\n",
        "\n",
        "      x_3x3 = self.relu3_1(self.bn3_1(self.conv3_1(x)))\n",
        "      x_5x5 = self.relu3_2(self.bn3_2(self.conv3_2(x)))\n",
        "      x_1x1 = self.relu3_3(self.bn3_3(self.conv3_3(x)))\n",
        "      x_pool = self.pool3_1(x)\n",
        "\n",
        "      x_3x3 = self.relu3_4(self.bn3_4(self.conv3_4(x_3x3)))\n",
        "      x_5x5 = self.relu3_5(self.bn3_5(self.conv3_5(x_5x5)))\n",
        "      x_pool = self.relu3_6(self.bn3_6(self.conv3_6(x_pool)))\n",
        "\n",
        "      x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n",
        "      x = self.avg_pool(x)\n",
        "\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.relu_fc1(self.fc1(x))\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf4Z8CojLeCS"
      },
      "source": [
        "Quantized version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MbK0UDCAXWxv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#padding='same' doesnt work for pytorch quantization processes\n",
        "# so we need to set up same convolutions manually\n",
        "def get_same_padding(i, k, s):\n",
        "  return (s*(i-1) + k-i)//2\n",
        "\n",
        "\n",
        "class QuantInceptionNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(QuantInceptionNet, self).__init__()\n",
        "        self.in_channels = 3\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(64)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=get_same_padding(32, 3, 1))\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        #block1\n",
        "\n",
        "        #1X1\n",
        "        #for 3x3\n",
        "        self.conv2_1 = nn.Conv2d(64, 32, kernel_size=1, padding=get_same_padding(16, 1, 1))\n",
        "        self.bn2_1 = nn.BatchNorm2d(32)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 5x5\n",
        "        self.conv2_2 = nn.Conv2d(64, 8, kernel_size=1, padding=get_same_padding(16, 1, 1))\n",
        "        self.bn2_2 = nn.BatchNorm2d(8)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "        #maxpool\n",
        "        self.pool2_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        #3x3\n",
        "        self.conv2_4 = nn.Conv2d(32, 64, kernel_size=3, padding=get_same_padding(16, 3, 1))\n",
        "        self.bn2_4 = nn.BatchNorm2d(64)\n",
        "        self.relu2_4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #5x5\n",
        "        self.conv2_5 = nn.Conv2d(8, 16, kernel_size=5, padding=get_same_padding(16, 5, 1))\n",
        "        self.bn2_5 = nn.BatchNorm2d(16)\n",
        "        self.relu2_5 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 1x1\n",
        "        self.conv2_3 = nn.Conv2d(64, 32, kernel_size=1, padding=get_same_padding(16, 1, 1))\n",
        "        self.bn2_3 = nn.BatchNorm2d(32)\n",
        "        self.relu2_3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #after maxpool\n",
        "        self.conv2_6 = nn.Conv2d(64, 16, kernel_size=1, padding=get_same_padding(16, 1, 1))\n",
        "        self.bn2_6 = nn.BatchNorm2d(16)\n",
        "        self.relu2_6 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #block2\n",
        "\n",
        "        #1X1\n",
        "        #for 3x3\n",
        "        self.conv3_1 = nn.Conv2d(128, 64, kernel_size=1, padding=get_same_padding(8, 1, 1))\n",
        "        self.bn3_1 = nn.BatchNorm2d(64)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 5x5\n",
        "        self.conv3_2 = nn.Conv2d(128, 16, kernel_size=1, padding=get_same_padding(8, 1, 1))\n",
        "        self.bn3_2 = nn.BatchNorm2d(16)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #for 1x1\n",
        "        self.conv3_3 = nn.Conv2d(128, 64, kernel_size=1, padding=get_same_padding(8, 1, 1))\n",
        "        self.bn3_3 = nn.BatchNorm2d(64)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #maxpool\n",
        "        self.pool3_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        #3x3\n",
        "        self.conv3_4 = nn.Conv2d(64, 128, kernel_size=3, padding=get_same_padding(8, 3, 1))\n",
        "        self.bn3_4 = nn.BatchNorm2d(128)\n",
        "        self.relu3_4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #5x5\n",
        "        self.conv3_5 = nn.Conv2d(16, 32, kernel_size=5, padding=get_same_padding(8, 5, 1))\n",
        "        self.bn3_5 = nn.BatchNorm2d(32)\n",
        "        self.relu3_5 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #after maxpool\n",
        "        self.conv3_6 = nn.Conv2d(128, 32, kernel_size=1, padding=get_same_padding(8, 1, 1))\n",
        "        self.bn3_6 = nn.BatchNorm2d(32)\n",
        "        self.relu3_6 = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        #final averagePool\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=8, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 2048)\n",
        "        self.relu_fc1 = nn.ReLU(inplace=True)\n",
        "        # self.fc2 = nn.Linear(4096, 4096)\n",
        "        # self.relu_fc2 = nn.ReLU(inplace=True)\n",
        "        self.fc3 = nn.Linear(2048, num_classes)\n",
        "\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.quant(x)\n",
        "      x = self.relu1_1(self.bn1_1(self.conv1_1(x)))\n",
        "      x = self.relu1_2(self.bn1_2(self.conv1_2(x)))\n",
        "      x = self.pool1(x)\n",
        "\n",
        "      x_3x3 = self.relu2_1(self.bn2_1(self.conv2_1(x)))\n",
        "      x_5x5 = self.relu2_2(self.bn2_2(self.conv2_2(x)))\n",
        "      x_1x1 = self.relu2_3(self.bn2_3(self.conv2_3(x)))\n",
        "      x_pool = self.pool2_1(x)\n",
        "\n",
        "      x_3x3 = self.relu2_4(self.bn2_4(self.conv2_4(x_3x3)))\n",
        "      x_5x5 = self.relu2_5(self.bn2_5(self.conv2_5(x_5x5)))\n",
        "      x_pool = self.relu2_6(self.bn2_6(self.conv2_6(x_pool)))\n",
        "\n",
        "      x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n",
        "      x = self.maxpool(x)\n",
        "\n",
        "      x_3x3 = self.relu3_1(self.bn3_1(self.conv3_1(x)))\n",
        "      x_5x5 = self.relu3_2(self.bn3_2(self.conv3_2(x)))\n",
        "      x_1x1 = self.relu3_3(self.bn3_3(self.conv3_3(x)))\n",
        "      x_pool = self.pool3_1(x)\n",
        "\n",
        "      x_3x3 = self.relu3_4(self.bn3_4(self.conv3_4(x_3x3)))\n",
        "      x_5x5 = self.relu3_5(self.bn3_5(self.conv3_5(x_5x5)))\n",
        "      x_pool = self.relu3_6(self.bn3_6(self.conv3_6(x_pool)))\n",
        "\n",
        "      x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n",
        "      x = self.avg_pool(x)\n",
        "\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.relu_fc1(self.fc1(x))\n",
        "      x = self.fc3(x)\n",
        "      x = self.dequant(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTWxr6tBXY05",
        "outputId": "320c0ca2-979d-4c46-b567-3bab9cbf34d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observers: 17\n"
          ]
        }
      ],
      "source": [
        "model = QuantInceptionNet()\n",
        "model.eval()\n",
        "checkpoint = torch.load(\"[PATH HERE]\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "\n",
        "model.qconfig = torch.quantization.QConfig(\n",
        "    activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8),\n",
        "    weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8)\n",
        ")\n",
        "\n",
        "modules = [\n",
        "    ['conv1_1', 'bn1_1', 'relu1_1'],\n",
        "    ['conv1_2', 'bn1_2', 'relu1_2'],\n",
        "    ['conv2_1', 'bn2_1', 'relu2_1'],\n",
        "    ['conv2_2', 'bn2_2', 'relu2_2'],\n",
        "    ['conv2_3', 'bn2_3', 'relu2_3'],\n",
        "    ['conv2_4', 'bn2_4', 'relu2_4'],\n",
        "    ['conv2_5', 'bn2_5', 'relu2_5'],\n",
        "    ['conv2_6', 'bn2_6', 'relu2_6'],\n",
        "    ['conv3_1', 'bn3_1', 'relu3_1'],\n",
        "    ['conv3_2', 'bn3_2', 'relu3_2'],\n",
        "    ['conv3_3', 'bn3_3', 'relu3_3'],\n",
        "    ['conv3_4', 'bn3_4', 'relu3_4'],\n",
        "    ['conv3_5', 'bn3_5', 'relu3_5'],\n",
        "    ['conv3_6', 'bn3_6', 'relu3_6'],\n",
        "    ['fc1', 'relu_fc1']\n",
        "]\n",
        "\n",
        "model = torch.quantization.fuse_modules(model, modules)\n",
        "\n",
        "model.eval()\n",
        "model_prepared = torch.quantization.prepare(model)\n",
        "print(\"Number of observers:\", len([m for m in model_prepared.modules() if 'Observer' in str(type(m))]))\n",
        "model_prepared.eval()\n",
        "with torch.no_grad():\n",
        "    for batch, _ in calib_loader:\n",
        "        batch = batch.to('cpu')\n",
        "        model_prepared(batch)\n",
        "\n",
        "quantized_model = torch.quantization.convert(model_prepared)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ug7CIPGubCP",
        "outputId": "c9d7ab11-0e1c-4828-ef43-a04952c2de5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuantInceptionNet(\n",
            "  (quant): QuantStub(\n",
            "    (activation_post_process): MinMaxObserver(min_val=-2.429065704345703, max_val=2.7537312507629395)\n",
            "  )\n",
            "  (dequant): DeQuantStub()\n",
            "  (conv1_1): ConvReLU2d(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=8.551780700683594)\n",
            "  )\n",
            "  (bn1_1): Identity()\n",
            "  (relu1_1): Identity()\n",
            "  (conv1_2): ConvReLU2d(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=4.8796067237854)\n",
            "  )\n",
            "  (bn1_2): Identity()\n",
            "  (relu1_2): Identity()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2_1): ConvReLU2d(\n",
            "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=3.6504292488098145)\n",
            "  )\n",
            "  (bn2_1): Identity()\n",
            "  (relu2_1): Identity()\n",
            "  (conv2_2): ConvReLU2d(\n",
            "    (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=2.349567413330078)\n",
            "  )\n",
            "  (bn2_2): Identity()\n",
            "  (relu2_2): Identity()\n",
            "  (pool2_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2_4): ConvReLU2d(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=3.7745652198791504)\n",
            "  )\n",
            "  (bn2_4): Identity()\n",
            "  (relu2_4): Identity()\n",
            "  (conv2_5): ConvReLU2d(\n",
            "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=3.0187625885009766)\n",
            "  )\n",
            "  (bn2_5): Identity()\n",
            "  (relu2_5): Identity()\n",
            "  (conv2_3): ConvReLU2d(\n",
            "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=4.092788219451904)\n",
            "  )\n",
            "  (bn2_3): Identity()\n",
            "  (relu2_3): Identity()\n",
            "  (conv2_6): ConvReLU2d(\n",
            "    (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=2.650824785232544)\n",
            "  )\n",
            "  (bn2_6): Identity()\n",
            "  (relu2_6): Identity()\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3_1): ConvReLU2d(\n",
            "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=3.1424593925476074)\n",
            "  )\n",
            "  (bn3_1): Identity()\n",
            "  (relu3_1): Identity()\n",
            "  (conv3_2): ConvReLU2d(\n",
            "    (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=2.90362811088562)\n",
            "  )\n",
            "  (bn3_2): Identity()\n",
            "  (relu3_2): Identity()\n",
            "  (conv3_3): ConvReLU2d(\n",
            "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=2.5879759788513184)\n",
            "  )\n",
            "  (bn3_3): Identity()\n",
            "  (relu3_3): Identity()\n",
            "  (pool3_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3_4): ConvReLU2d(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=7.283628940582275)\n",
            "  )\n",
            "  (bn3_4): Identity()\n",
            "  (relu3_4): Identity()\n",
            "  (conv3_5): ConvReLU2d(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=8.581740379333496)\n",
            "  )\n",
            "  (bn3_5): Identity()\n",
            "  (relu3_5): Identity()\n",
            "  (conv3_6): ConvReLU2d(\n",
            "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=9.253817558288574)\n",
            "  )\n",
            "  (bn3_6): Identity()\n",
            "  (relu3_6): Identity()\n",
            "  (avg_pool): AvgPool2d(kernel_size=8, stride=2, padding=0)\n",
            "  (fc1): LinearReLU(\n",
            "    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.803289532661438)\n",
            "  )\n",
            "  (relu_fc1): Identity()\n",
            "  (fc3): Linear(\n",
            "    in_features=2048, out_features=10, bias=True\n",
            "    (activation_post_process): MinMaxObserver(min_val=-9.08742618560791, max_val=20.020727157592773)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOcCu0sc0VFT",
        "outputId": "40acd678-ba2b-4a5c-b170-6f28e5664885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelfp32 = InceptionNet()\n",
        "checkpoint = torch.load(\"[PATH HERE]\", map_location=\"cpu\")\n",
        "modelfp32.load_state_dict(checkpoint['model_state'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mojgvGavXtor",
        "outputId": "37603e20-62fd-4178-916e-5978051aab66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-91c03078d23d>:132: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:168.)\n",
            "  x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n",
            "<ipython-input-14-91c03078d23d>:144: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:168.)\n",
            "  x = torch.cat([x_1x1, x_3x3, x_5x5, x_pool], dim=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized ACC:  80.11 Average Inference on Quantized:  0.002119420337677002\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "quantized_model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = quantized_model(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"Quantized ACC: \", acc*100, \"Average Inference on Quantized: \", t_av)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SenvQsWbfGrB",
        "outputId": "d4d44508-7c9f-428c-d2ce-eeb7f1f118f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fp32 ACC:  80.36999999999999 Average Inference on fp32:  0.004519141173362732\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "modelfp32.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = modelfp32(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"fp32 ACC: \", acc*100, \"Average Inference on fp32: \", t_av)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqrmIeC1LzSX"
      },
      "source": [
        "# Our Scores\n",
        "Accuracy Retention = (Quantized Accuracy / Original Accuracy) × 100 = 99.68%\n",
        "\n",
        "Inference Time=( Original Inference Time/ Quantized Inference Time) = 2.133x\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
