{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ryFBsbciXJwl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AHVvqUxXKmh",
        "outputId": "890c273f-9e99-427a-fe26-3f45a3ea651b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/rn/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 63.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/rn/cifar-10-python.tar.gz to /content/rn\n"
          ]
        }
      ],
      "source": [
        "#data loader adopted from training\n",
        "def data_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    random_seed=42,\n",
        "                    valid_size=0.1,\n",
        "                    shuffle=True,\n",
        "                    test=False):\n",
        "\n",
        "        normalize = transforms.Normalize(\n",
        "            mean=[0.4914, 0.4822, 0.4465],\n",
        "            std=[0.2023, 0.1994, 0.2010],\n",
        "        )\n",
        "\n",
        "        # define transforms\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        download = not os.path.exists(os.path.join(data_dir, \"cifar-10-batches-py\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if test:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=False,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "        else:\n",
        "          dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=True,\n",
        "            download=download, transform=transform,\n",
        "          )\n",
        "          indices = list(range(0, len(dataset)))\n",
        "          np.random.seed(42)\n",
        "          np.random.shuffle(indices)\n",
        "          data = Subset(dataset,indices)\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            data, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "\n",
        "calib_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=32,\n",
        "                                  test=False)\n",
        "test_loader = data_loader(data_dir='/content/rn',\n",
        "                                  batch_size=32,\n",
        "                                  test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We load the original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q2f1lhCRzhHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG19, self).__init__()\n",
        "        self.in_channels = 3\n",
        "\n",
        "        # Convolutional layers (atomic definition without Sequential)\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_4 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_4 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_4 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 4096)\n",
        "        self.relu_fc1 = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.relu_fc2 = nn.ReLU(inplace=True)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "        # Weight initialization\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1_1(self.conv1_1(x))\n",
        "        x = self.relu1_2(self.conv1_2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu2_1(self.conv2_1(x))\n",
        "        x = self.relu2_2(self.conv2_2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.relu3_1(self.conv3_1(x))\n",
        "        x = self.relu3_2(self.conv3_2(x))\n",
        "        x = self.relu3_3(self.conv3_3(x))\n",
        "        x = self.relu3_4(self.conv3_4(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.relu4_1(self.conv4_1(x))\n",
        "        x = self.relu4_2(self.conv4_2(x))\n",
        "        x = self.relu4_3(self.conv4_3(x))\n",
        "        x = self.relu4_4(self.conv4_4(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.relu5_1(self.conv5_1(x))\n",
        "        x = self.relu5_2(self.conv5_2(x))\n",
        "        x = self.relu5_3(self.conv5_3(x))\n",
        "        x = self.relu5_4(self.conv5_4(x))\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu_fc1(self.fc1(x))\n",
        "        x = self.relu_fc2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We then edit the original model to be suitable for quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MbK0UDCAXWxv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class QuantVGG19(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(QuantVGG19, self).__init__()\n",
        "        self.in_channels = 3\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "        # Convolutional layers (atomic definition without Sequential)\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.relu3_4 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu4_4 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.relu5_4 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 4096)\n",
        "        self.relu_fc1 = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.relu_fc2 = nn.ReLU(inplace=True)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "        # Weight initialization\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.relu1_1(self.conv1_1(x))\n",
        "        x = self.relu1_2(self.conv1_2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu2_1(self.conv2_1(x))\n",
        "        x = self.relu2_2(self.conv2_2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.relu3_1(self.conv3_1(x))\n",
        "        x = self.relu3_2(self.conv3_2(x))\n",
        "        x = self.relu3_3(self.conv3_3(x))\n",
        "        x = self.relu3_4(self.conv3_4(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.relu4_1(self.conv4_1(x))\n",
        "        x = self.relu4_2(self.conv4_2(x))\n",
        "        x = self.relu4_3(self.conv4_3(x))\n",
        "        x = self.relu4_4(self.conv4_4(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.relu5_1(self.conv5_1(x))\n",
        "        x = self.relu5_2(self.conv5_2(x))\n",
        "        x = self.relu5_3(self.conv5_3(x))\n",
        "        x = self.relu5_4(self.conv5_4(x))\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu_fc1(self.fc1(x))\n",
        "        x = self.relu_fc2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the original trained models into the updated model architecture.\n",
        "\n",
        "we then add observers to see how our calibration data is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTWxr6tBXY05",
        "outputId": "42c606cb-1c54-41a4-c02a-96ac98fe0668"
      },
      "outputs": [],
      "source": [
        "model = QuantVGG19()\n",
        "model.eval()\n",
        "checkpoint = torch.load(\"/content/vgg19_checkpoint3_9.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "#model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "#model.qconfig = torch.quantization.default_qconfig\n",
        "model.qconfig = torch.quantization.QConfig(\n",
        "    activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8),\n",
        "    weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8)\n",
        ")\n",
        "\n",
        "modules = [\n",
        "    ['conv1_1', 'relu1_1'],\n",
        "    ['conv1_2', 'relu1_2'],\n",
        "    ['conv2_1', 'relu2_1'],\n",
        "    ['conv2_2', 'relu2_2'],\n",
        "    ['conv3_1', 'relu3_1'],\n",
        "    ['conv3_2', 'relu3_2'],\n",
        "    ['conv3_3', 'relu3_3'],\n",
        "    ['conv3_4', 'relu3_4'],\n",
        "    ['conv4_1', 'relu4_1'],\n",
        "    ['conv4_2', 'relu4_2'],\n",
        "    ['conv4_3', 'relu4_3'],\n",
        "    ['conv4_4', 'relu4_4'],\n",
        "    ['conv5_1', 'relu5_1'],\n",
        "    ['conv5_2', 'relu5_2'],\n",
        "    ['conv5_3', 'relu5_3'],\n",
        "    ['conv5_4', 'relu5_4'],\n",
        "    ['fc1', 'relu_fc1'],\n",
        "    ['fc2', 'relu_fc2']\n",
        "]\n",
        "\n",
        "\n",
        "model = torch.quantization.fuse_modules(model, modules)\n",
        "model.eval()\n",
        "model_prepared = torch.quantization.prepare(model)\n",
        "print(\"Number of observers:\", len([m for m in model_prepared.modules() if 'Observer' in str(type(m))]))\n",
        "model_prepared.eval()\n",
        "with torch.no_grad():\n",
        "    for batch, _ in calib_loader:\n",
        "        batch = batch.to('cpu')\n",
        "        model_prepared(batch)\n",
        "\n",
        "quantized_model = torch.quantization.convert(model_prepared)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the original model for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOcCu0sc0VFT",
        "outputId": "ce83fe46-9c32-4417-b822-3ac569f19c92"
      },
      "outputs": [],
      "source": [
        "modelfp32 = VGG19()\n",
        "checkpoint = torch.load(\"/content/vgg19_checkpoint3_9.pth\", map_location=\"cpu\")\n",
        "modelfp32.load_state_dict(checkpoint['model_state'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mojgvGavXtor",
        "outputId": "871e5a77-c741-4626-81f3-bbb2b1f9482f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized ACC:  70.73 Average Inference on Quantized:  0.008483899807929993\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "quantized_model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = quantized_model(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"Quantized ACC: \", acc*100, \"Average Inference on Quantized: \", t_av)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaaoPetvqAF",
        "outputId": "0db7d2dd-f3b8-4500-e18d-fd4b6688307d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fp32 ACC:  71.11 Average Inference on fp32:  0.018399335145950317\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "total=0\n",
        "correct=0\n",
        "total_time = 0\n",
        "modelfp32.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        t0 = time.time()\n",
        "        outputs = modelfp32(inputs)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1-t0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "acc = correct/total\n",
        "t_av = total_time/total #average inference time per image\n",
        "print(\"fp32 ACC: \", acc*100, \"Average Inference on fp32: \", t_av)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Our Scores\n",
        "\n",
        "Accuracy Retention = (Quantized Accuracy / Original Accuracy) × 100\n",
        "                   = *99.46%*\n",
        "\n",
        "Inference Time=( Original Inference Time/ Original Inference Time)\n",
        "              = *2.168x*\n",
        "\n",
        "Wow, We get amazing inference improvement in VGG19!!!!\n",
        "\n",
        "Overall = Accuracy Retention/100 + Inference Speedup/5 = 1.4266 \n",
        " \n",
        "Lets look at the others!!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
